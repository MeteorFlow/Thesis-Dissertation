%\subsection{Giới thiệu}

Apache Airflow™ là một nền tảng mã nguồn mở giúp quản lý các luồng dữ liệu (data flow) của các hệ thống liên quan đến dữ liệu. Đối diện với thách thức ngày càng gia tăng về quản lý data pipeline (đường ống dữ liệu), Airflow trở thành một giải pháp toàn diện, giúp tự động hóa và tối ưu hóa quy trình làm việc liên quan đến dữ liệu.\cite{airflow}

Airflow không chỉ giúp xác định và quản lý thời gian bắt đầu và kết thúc của mỗi data pipeline mà còn cung cấp khả năng theo dõi chính xác và chi tiết về kết quả của mỗi công việc. Điều này trở nên quan trọng đặc biệt khi cần đảm bảo tính toàn vẹn và độ tin cậy của dữ liệu được xử lý.

Với khả năng xác định mối quan hệ phức tạp giữa các công việc thông qua mô hình Directed Acyclic Graph (DAG), Airflow cho phép người quản trị có kiểm soát chặt chẽ và linh hoạt hơn trong việc xử lý quy trình làm việc. Sự tích hợp mạnh mẽ với hệ thống logs giúp theo dõi và phân tích hoạt động một cách chi tiết, hỗ trợ trong quá trình xử lý sự cố và đảm bảo rằng mọi quy trình được thực hiện theo kỳ vọng.

Đồng thời, khả năng linh hoạt trong việc lên lịch làm cho Airflow trở thành một công cụ ưu việt cho việc quản lý thời gian và tài nguyên. Sự tích hợp mạnh mẽ với nhiều nguồn dữ liệu và khả năng mở rộng thông qua plug-in giúp Airflow đáp ứng được đa dạng nhu cầu trong quy trình xử lý dữ liệu và tự động hóa công việc.

Apache Airflow không chỉ đem lại hiệu suất mạnh mẽ mà còn mang đến sự linh hoạt và tính năng kỹ thuật tối ưu cho quy trình xử lý dữ liệu. Với khả năng quản lý thời gian, tích hợp logs mạnh mẽ, linh hoạt trong việc lên lịch và khả năng mở rộng, Airflow là sự lựa chọn hàng đầu để nâng cao hiệu suất và kiểm soát trong quy trình xử lý dữ liệu.

%\subsection{Mục đích sử dụng}

%Khi số lượng các data pipeline (đường ống dữ liệu) của một hệ thống tăng lên, sẽ có nhiều vấn đề được đặt ra:

%\begin{itemize}
    %\item Làm cách nào để quản lí (orchestrate) tất cả những luồng ETL hiện có trong toàn bộ hệ thống. Một trong số đó có thể kể đến như:
    %\begin{itemize}
        %\item Thời gian bắt đầu
        %\item Thời lượng chạy
        %\item Kết quả của những lần chạy
        %\item Mối quan hệ giữa từng data pipeline với nhau: chạy tuần tự, chạy song song, ...
    %\end{itemize}
    %\item Cần xây dựng một hệ thống để centralize (tổng hợp lại) tất cả các logs (nhật ký hoạt động) của từng flow. Trong tình huống có sự cố diễn ra: dữ liệu không chưa theo format (định dạng), các hệ thống có liên quan không hoạt động bình thường, hay quá trình ETL đã đi đến bước nào, ... người vận hành có cơ sở để suy cứu và khắc phục.
%\end{itemize}